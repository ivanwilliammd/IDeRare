{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (2021.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: o365 2.0.16 has a non-standard dependency specifier tzlocal<3.*,>=1.5.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of o365 or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (6.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: o365 2.0.16 has a non-standard dependency specifier tzlocal<3.*,>=1.5.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of o365 or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hpo3 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (1.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: o365 2.0.16 has a non-standard dependency specifier tzlocal<3.*,>=1.5.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of o365 or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pyyaml\n",
    "!pip install hpo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyhpo import Ontology, HPOSet, Omim, stats\n",
    "import yaml\n",
    "\n",
    "Ontology(os.path.join(os.getcwd(), 'phenotype', 'rawdl_20240310'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the folder path for phenotype data source\n",
    "phenotype_folder = os.path.join(os.getcwd(), 'phenotype', 'subset')\n",
    "\n",
    "# Declare 7 Files\n",
    "icd10omim = 'icd102omim_subset.tsv'\n",
    "loinc2hpo = 'loinc2hpo_standardized.tsv'\n",
    "omim2hpo = 'omim2hpo_subset.tsv'\n",
    "orpha2omim = 'orpha2omim_subset.tsv'\n",
    "orpha2hpo = 'orpha2hpo_subset.tsv'\n",
    "snomed2hpo = 'snomed2hpo_subset.tsv'\n",
    "snomed2orpha = 'snomed2orpha_subset.tsv'\n",
    "\n",
    "# iderare yaml configuration file\n",
    "yaml_file = 'iderare.yaml'\n",
    "\n",
    "# Clinical data dummy in txt format separated with new line\n",
    "clinical_data = 'clinical_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the clinical data and parse the data\n",
    "icd10omim_df = pd.read_csv(os.path.join(phenotype_folder, icd10omim), sep='\\t')\n",
    "loinc2hpo_df = pd.read_csv(os.path.join(phenotype_folder, loinc2hpo), sep='\\t')\n",
    "omim2hpo_df = pd.read_csv(os.path.join(phenotype_folder, omim2hpo), sep='\\t')\n",
    "orpha2omim_df = pd.read_csv(os.path.join(phenotype_folder, orpha2omim), sep='\\t')\n",
    "orpha2hpo_df = pd.read_csv(os.path.join(phenotype_folder, orpha2hpo), sep='\\t')\n",
    "snomed2hpo_df = pd.read_csv(os.path.join(phenotype_folder, snomed2hpo), sep='\\t')\n",
    "snomed2orpha_df = pd.read_csv(os.path.join(phenotype_folder, snomed2orpha), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SNOMEDCT:65959000',\n",
       " 'SNOMEDCT:11179002',\n",
       " 'ICD-10:E75.2',\n",
       " 'SNOMEDCT:258211005',\n",
       " 'SNOMEDCT:80515008',\n",
       " 'SNOMEDCT:389026000',\n",
       " 'LOINC:2862-1|L',\n",
       " 'LOINC:718-7|L']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read line from clinical_data and parse the data to list\n",
    "with open(clinical_data, 'r') as file:\n",
    "    clinical_data_list = file.read().splitlines()\n",
    "\n",
    "clinical_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_elements(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    return list(set1.intersection(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO Parser for Clinical Finding Related Terminology such as SNOMED, LOINC\n",
    "def hpo_parser(clinical_data, df):    \n",
    "    print('Trying to parse HPO from terminology', clinical_data)\n",
    "    \n",
    "    # LOINC case\n",
    "    if 'LOINC:' in clinical_data:\n",
    "        loinc_split = clinical_data.split('|')\n",
    "        # Ensure that the forwarded data contain both LOINC and its interpretation\n",
    "        if len(loinc_split) == 2:\n",
    "            loinc = loinc_split[0]\n",
    "            interpretation = loinc_split[1]\n",
    "            \n",
    "            # Handling if LOINC code not found in the database\n",
    "            if loinc not in df['loinc'].unique() :\n",
    "                print('LOINC data is not found in the database, please check the exact LOINC code.')\n",
    "                loinc_sugg = df[df['loinc'].str.contains(loinc.strip('LOINC:'))]['loinc'].drop_duplicates()\n",
    "                print('Did you mean any of this code:', (', ').join(loinc_sugg.values) , '?\\n')\n",
    "                return []\n",
    "            \n",
    "            loinc_hpo = df[df['loinc'] == loinc]\n",
    "\n",
    "            # Handling if interpretation not suitable for the LOINC code\n",
    "            if interpretation not in loinc_hpo['interpretation'].unique() :\n",
    "                print('Interpretation is invalid, please check if you have used correct interpretation.')\n",
    "                interpretation_sugg = df[df['loinc']==loinc]['interpretation'].drop_duplicates()\n",
    "                print('Available interpretation for code', loinc, ' : ', (' or ').join(interpretation_sugg.values) , '\\n')\n",
    "                return []\n",
    "            \n",
    "            loinc_hpo = loinc_hpo[loinc_hpo['interpretation'] == interpretation]['hpoTermId'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', loinc_hpo, '\\n')\n",
    "            return loinc_hpo\n",
    "        else:\n",
    "            print('LOINC data is missing either code / interpretation.')\n",
    "            print('Example : LOINC:721-1|H for Qn lab examination OR LOINC:721-1|NEG for Nominal / Ordinal Lab Examination', '\\n')\n",
    "            return []\n",
    "        \n",
    "    # SNOMED-CT case\n",
    "    elif 'SNOMEDCT:' in clinical_data:\n",
    "        if clinical_data not in df['SNOMED_CT_ID'].unique() :\n",
    "            print('This SNOMED-CT code is not a clinical finding mapped with HPO, please check the SNOMED to OMIM for diagnosis mapping.')\n",
    "            snomed_sugg = df[df['SNOMED_CT_ID'].str.contains(clinical_data.strip('SNOMEDCT:'))]['SNOMED_CT_ID'].drop_duplicates()\n",
    "            print('Sugggestion : It is possible that you mean any of this code:', (', ').join(snomed_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            snomed_hpo = df[df['SNOMED_CT_ID'] == clinical_data]['HPO_ID'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(snomed_hpo), ' HPO code : ', (', ').join(snomed_hpo), '\\n')\n",
    "            return snomed_hpo\n",
    "        \n",
    "    # Not recognized case\n",
    "    else:\n",
    "        print('The terminology is not recognized, please check if you have used correct terminology.')\n",
    "        print('Example : LOINC:2862-1|L for Qn lab examination OR LOINC:725-2|NEG for categoric lab examination of SNOMEDCT:48610005 for Clinical Finding', '\\n')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snomed_orpha_parser(clinical_data, df):\n",
    "    print('Trying to parse ORPHA from SNOMED-CT', clinical_data)\n",
    "    \n",
    "    if 'SNOMEDCT:' in clinical_data:\n",
    "        if clinical_data not in df['code'].unique() :\n",
    "            print('This SNOMED-CT code is not a clinical finding mapped with ORPHA, please check the SNOMED to ORPHA for diagnosis mapping.')\n",
    "            snomed_sugg = df[df['code'].str.contains(clinical_data.strip('SNOMEDCT:'))]['code'].drop_duplicates()\n",
    "            print('Sugggestion : It is possible that you mean any of this code:', (', ').join(snomed_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            snomed_orpha = df[df['code'] == clinical_data]['orphanet_map'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(snomed_orpha), ' ORPHA code : ', (', ').join(snomed_orpha), '\\n')\n",
    "            return snomed_orpha\n",
    "        \n",
    "    else :\n",
    "        print('The terminology is not recognized, please check if you have used correct terminology.')\n",
    "        print('Allowable format : SNOMEDCT disorder semantic only SNOMEDCT:1212005', '\\n')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMIM Parser used for diagnosis related terminology such as ICD-10, ORPHA, SNOMED-CT\n",
    "def omim_parser(clinical_data,df):\n",
    "    print('Trying to parse OMIM from terminology', clinical_data)\n",
    "\n",
    "    # ICD-10 case\n",
    "    if 'ICD-10:' in clinical_data:\n",
    "        if clinical_data not in df['ICD10'].unique() :\n",
    "            print('ICD-10 data is not found in the database, please check the exact ICD-10 code.')\n",
    "            icd_sugg = df[df['ICD10'].str.contains(clinical_data.strip('ICD-10:'))]['ICD10'].drop_duplicates()\n",
    "            print('Did you mean any of this code:', (', ').join(icd_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            icd_omim = df[df['ICD10'] == clinical_data]['OMIM'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(icd_omim), ' OMIM code : ', (', ').join(icd_omim), '\\n')\n",
    "            return icd_omim\n",
    "        \n",
    "    # ORPHA case\n",
    "    elif 'ORPHA:' in clinical_data:\n",
    "        if clinical_data not in df['ORPHA'].unique() :\n",
    "            print('ORPHA data is not found in the database, please check the exact ORPHA code.')\n",
    "            orpha_sugg = df[df['ORPHA'].str.contains(clinical_data.strip('ORPHA:'))]['ORPHA'].drop_duplicates()\n",
    "            print('Did you mean any of this code:', (', ').join(orpha_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            orpha_hpo = df[df['ORPHA'] == clinical_data]['OMIM'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(orpha_hpo), ' OMIM code : ', (', ').join(orpha_hpo), '\\n')\n",
    "            return orpha_hpo\n",
    "    \n",
    "    else:\n",
    "        print('The terminology is not recognized, please check the input format.')\n",
    "        print('Allowable format is : ICD-10:xxxx OR ORPHA:xxxxx for clinical disorder', '\\n')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to parse HPO from terminology LOINC:2862-1|L\n",
      "Parsing of LOINC:2862-1|L successful with result of : ['HP:0003073'] \n",
      "\n",
      "Trying to parse HPO from terminology SNOMEDCT:249627005\n",
      "Parsing of SNOMEDCT:249627005 successful with result of : 1  HPO code :  HP:0002249 \n",
      "\n",
      "Result of : 2 HPO code(s) from loinc_hpo_example and snomed_hpo_example\n",
      "\n",
      "Trying to parse OMIM from terminology ICD-10:E75.2\n",
      "Parsing of ICD-10:E75.2 successful with result of : 46  OMIM code :  OMIM:228000, OMIM:603896, OMIM:203450, OMIM:616140, OMIM:613926, OMIM:613925, OMIM:604004, OMIM:608804, OMIM:612233, OMIM:260600, OMIM:300523, OMIM:312080, OMIM:611721, OMIM:615281, OMIM:272200, OMIM:221790, OMIM:607616, OMIM:245200, OMIM:611722, OMIM:613724, OMIM:231005, OMIM:607694, OMIM:257200, OMIM:615889, OMIM:617762, OMIM:271900, OMIM:250100, OMIM:231000, OMIM:213900, OMIM:257220, OMIM:607625, OMIM:608013, OMIM:617899, OMIM:612438, OMIM:221820, OMIM:169500, OMIM:249900, OMIM:156310, OMIM:610539, OMIM:230900, OMIM:612951, OMIM:609136, OMIM:230800, OMIM:615651, OMIM:617560, OMIM:301500 \n",
      "\n",
      "Trying to parse OMIM from terminology ORPHA:848\n",
      "Parsing of ORPHA:848 successful with result of : 2  OMIM code :  OMIM:613985, OMIM:603902 \n",
      "\n",
      "Trying to parse ORPHA from SNOMED-CT SNOMEDCT:11179002\n",
      "Parsing of SNOMEDCT:11179002 successful with result of : 1  ORPHA code :  ORPHA:367 \n",
      "\n",
      "Trying to parse OMIM from terminology ORPHA:367\n",
      "Parsing of ORPHA:367 successful with result of : 2  OMIM code :  OMIM:263570, OMIM:232500 \n",
      "\n",
      "Result of : 4 OMIM code(s) from Diagnosis Code\n",
      "Result of : 4 unique OMIM code(s) from Diagnosis Code\n"
     ]
    }
   ],
   "source": [
    "# Example of hpo_parser for Clinical Finding (LOINC & SNOMED)\n",
    "hpo_result = []\n",
    "loinc_hpo_example = hpo_parser('LOINC:2862-1|L', loinc2hpo_df)\n",
    "snomed_hpo_example = hpo_parser('SNOMEDCT:249627005', snomed2hpo_df)\n",
    "\n",
    "# Initiate List or Append\n",
    "hpo_result.extend(loinc_hpo_example)\n",
    "hpo_result.extend(snomed_hpo_example)\n",
    "\n",
    "print(\"Result of :\", len(hpo_result), \"HPO code(s) from loinc_hpo_example and snomed_hpo_example\\n\")\n",
    "\n",
    "# Example of OMIM Parser for Diagnosis\n",
    "omim_hpo_result = []\n",
    "icd_omim_example = omim_parser('ICD-10:E75.2', icd10omim_df)\n",
    "orpha_omim_example = omim_parser('ORPHA:848', orpha2omim_df)\n",
    "snomed_orpha_example = snomed_orpha_parser('SNOMEDCT:11179002', snomed2orpha_df)\n",
    "\n",
    "snomed_omim_example = []\n",
    "for i in range(len(snomed_orpha_example)) :\n",
    "    snomed_omim_example = snomed_omim_example + omim_parser(snomed_orpha_example[i], orpha2omim_df)\n",
    "\n",
    "# Extend the result, but exclude the ICD OMIM since the code itself is unspecific and give too many unspecific result\n",
    "# omim_hpo_result.extend(icd_omim_example)\n",
    "omim_hpo_result.extend(orpha_omim_example)\n",
    "omim_hpo_result.extend(snomed_omim_example)\n",
    "\n",
    "print(\"Result of :\", len(omim_hpo_result), \"OMIM code(s) from Diagnosis Code\")\n",
    "print(\"Result of :\", len(set(omim_hpo_result)), \"unique OMIM code(s) from Diagnosis Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omim_hpo_intersecter(omim_list, df, diagnosis_phen_sim_threshold=0.8):\n",
    "    ## Explanation : \n",
    "    \n",
    "    # 1. diagnosis_phen_sim_threshold is a threshold to determine the intersection of HPO between the diagnosis\n",
    "    # Suppose you have 10 OMIM diagnosis code, and the threshold is 0.9, then the HPO code returned would be the one that occur at least 9 times\n",
    "    # If the threshold is 0.5, then the HPO code returned would be the one that occur at least 5 times\n",
    "    \n",
    "    # Number the OMIM code that will be check as phenotype relationship \n",
    "    threshold = diagnosis_phen_sim_threshold * len(omim_list)\n",
    "    \n",
    "    # Result out the data that at least occur more than threshold\n",
    "    if len(omim_list) > 0:\n",
    "        omim_list = set(omim_list)\n",
    "        omim_hpo = df[df['disease_id'].isin(omim_list)]\n",
    "\n",
    "        # Get Index of valuecounts that is more than threshold\n",
    "        hpo_count = omim_hpo['hpo_id'].value_counts()\n",
    "        # Get the count of HPO code\n",
    "        print(hpo_count)\n",
    "\n",
    "        # Get the HPO code(s) that is on the highest counts or more than threshold\n",
    "        omim_hpo = omim_hpo[omim_hpo['hpo_id'].isin(hpo_count)]\n",
    "        disease_id = omim_hpo['disease_id'].drop_duplicates().to_list()\n",
    "\n",
    "        # Deduplicate to get the set only\n",
    "        hpo_set = set(omim_hpo['hpo_id'].to_list())\n",
    "        disease_set = set(disease_id)\n",
    "        \n",
    "        return hpo_set, disease_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dendogram(omim_sets):\n",
    "    linkage_disease = []\n",
    "    for item in omim_sets:\n",
    "        try : \n",
    "            disease = Omim.get(int(item.strip('OMIM:')))\n",
    "            linkage_disease.append(disease)\n",
    "        except:\n",
    "            print('OMIM code', item, 'is skipped.')\n",
    "            continue\n",
    "        # disease.hpo_set()\n",
    "        \n",
    "    # Using diseases and creating a Tuple of (Disease Name, HPOSet) for each\n",
    "    diseases = [(d.name, HPOSet(list(d.hpo)).remove_modifier()) for d in linkage_disease]\n",
    "\n",
    "    # Creating one list with all HPOSets\n",
    "    disease_sets = [d[1] for d in diseases]\n",
    "    # And one list with the names of diseases\n",
    "    names = [d[0] for d in diseases]\n",
    "\n",
    "    # Cluster the diseases using default settings\n",
    "    lnk = stats.linkage(disease_sets)\n",
    "\n",
    "    # For plotting, you can use `scipy`\n",
    "    import scipy.cluster\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    scipy.cluster.hierarchy.dendrogram(lnk, labels=names, show_contracted=True, leaf_font_size=12, leaf_rotation=90, color_threshold=0.5)\n",
    "    plt.axhline(y=0.5, c='grey', lw=1, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP:0000005    2\n",
      "HP:0001438    2\n",
      "HP:0034345    2\n",
      "HP:0002240    2\n",
      "HP:0003271    2\n",
      "             ..\n",
      "HP:0003596    1\n",
      "HP:0001560    1\n",
      "HP:0031064    1\n",
      "HP:0011804    1\n",
      "HP:0002922    1\n",
      "Name: hpo_id, Length: 168, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hpo_set, disease_set = omim_hpo_intersecter(omim_hpo_result, omim2hpo_df, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HPOSet.from_serialized(\"2249+3073\")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpo_set = HPOSet.from_queries(hpo_result)\n",
    "hpo_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease BETA-THALASSEMIA with OMIM code 613985\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the OMIM to HPO Set Object\n",
    "linkage_disease = []\n",
    "for item in omim_hpo_result:\n",
    "    try : \n",
    "        disease = Omim.get(int(item.strip('OMIM:')))\n",
    "        linkage_disease.append(disease)\n",
    "    except:\n",
    "        print('OMIM code', item, 'is skipped.')\n",
    "        continue\n",
    "\n",
    "omim_sets = [o.hpo_set() for o in linkage_disease]\n",
    "\n",
    "# Search prospective disease with similarity with HPO\n",
    "similarities = hpo_set.similarity_scores(omim_sets, method='graphic', combine='funSimMax')\n",
    "matrix = np.array(similarities)\n",
    "\n",
    "\n",
    "# # Search similarity within the diagnosis\n",
    "\n",
    "# similarity_result = []\n",
    "# for i in range(len(omim_sets)):\n",
    "#     similarities = omim_sets[i].similarity_scores(omim_sets)\n",
    "#     similarity_result.append(similarities)\n",
    "\n",
    "# # Filter based on threshold\n",
    "# matrix = np.array(similarity_result)\n",
    "\n",
    "# Count the number of elements greater than 0.8 in each column\n",
    "# count_per_column = np.sum(matrix > 0.8, axis=0)\n",
    "\n",
    "# # Find the indices of columns where at least majority consent 0.8 or is the maximum likelihood column\n",
    "# selected_columns = np.where(np.logical_or(count_per_column > 0, count_per_column == np.max(count_per_column)))[0]\n",
    "# print(selected_columns)\n",
    "\n",
    "for i in selected_columns :\n",
    "    print('Disease', linkage_disease[i].name, 'with OMIM code', linkage_disease[i].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03288199, 0.03258756, 0.05292881, 0.07355185])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
