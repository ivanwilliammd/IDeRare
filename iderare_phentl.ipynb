{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: o365 2.0.16 has a non-standard dependency specifier tzlocal<3.*,>=1.5.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of o365 or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (6.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: o365 2.0.16 has a non-standard dependency specifier tzlocal<3.*,>=1.5.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of o365 or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the folder path for phenotype data source\n",
    "phenotype_folder = os.path.join(os.getcwd(), 'phenotype', 'subset')\n",
    "\n",
    "# Declare 7 Files\n",
    "icd10omim = 'icd102omim_subset.tsv'\n",
    "loinc2hpo = 'loinc2hpo_standardized.tsv'\n",
    "omim2hpo = 'omim2hpo_subset.tsv'\n",
    "orpha2omim = 'orpha2omim_subset.tsv'\n",
    "orpha2hpo = 'orpha2hpo_subset.tsv'\n",
    "snomed2hpo = 'snomed2hpo_subset.tsv'\n",
    "snomed2orpha = 'snomed2orpha_subset.tsv'\n",
    "\n",
    "# iderare yaml configuration file\n",
    "yaml_file = 'iderare.yaml'\n",
    "\n",
    "# Clinical data dummy in txt format separated with new line\n",
    "clinical_data = 'clinical_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the clinical data and parse the data\n",
    "icd10omim_df = pd.read_csv(os.path.join(phenotype_folder, icd10omim), sep='\\t')\n",
    "loinc2hpo_df = pd.read_csv(os.path.join(phenotype_folder, loinc2hpo), sep='\\t')\n",
    "omim2hpo_df = pd.read_csv(os.path.join(phenotype_folder, omim2hpo), sep='\\t')\n",
    "orpha2omim_df = pd.read_csv(os.path.join(phenotype_folder, orpha2omim), sep='\\t')\n",
    "orpha2hpo_df = pd.read_csv(os.path.join(phenotype_folder, orpha2hpo), sep='\\t')\n",
    "snomed2hpo_df = pd.read_csv(os.path.join(phenotype_folder, snomed2hpo), sep='\\t')\n",
    "snomed2orpha_df = pd.read_csv(os.path.join(phenotype_folder, snomed2orpha), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SNOMEDCT:65959000',\n",
       " 'SNOMEDCT:11179002',\n",
       " 'ICD-10:E75.2',\n",
       " 'SNOMEDCT:258211005',\n",
       " 'SNOMEDCT:80515008',\n",
       " 'SNOMEDCT:389026000',\n",
       " 'LOINC:2862-1|L',\n",
       " 'LOINC:718-7|L']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read line from clinical_data and parse the data to list\n",
    "with open(clinical_data, 'r') as file:\n",
    "    clinical_data_list = file.read().splitlines()\n",
    "\n",
    "clinical_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_elements(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    return list(set1.intersection(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO Parser for Clinical Finding Related Terminology such as SNOMED, LOINC\n",
    "def hpo_parser(clinical_data, df):    \n",
    "    print('Trying to parse HPO from terminology', clinical_data)\n",
    "    \n",
    "    # LOINC case\n",
    "    if 'LOINC:' in clinical_data:\n",
    "        loinc_split = clinical_data.split('|')\n",
    "        # Ensure that the forwarded data contain both LOINC and its interpretation\n",
    "        if len(loinc_split) == 2:\n",
    "            loinc = loinc_split[0]\n",
    "            interpretation = loinc_split[1]\n",
    "            \n",
    "            # Handling if LOINC code not found in the database\n",
    "            if loinc not in df['loinc'].unique() :\n",
    "                print('LOINC data is not found in the database, please check the exact LOINC code.')\n",
    "                loinc_sugg = df[df['loinc'].str.contains(loinc.strip('LOINC:'))]['loinc'].drop_duplicates()\n",
    "                print('Did you mean any of this code:', (', ').join(loinc_sugg.values) , '?\\n')\n",
    "                return []\n",
    "            \n",
    "            loinc_hpo = df[df['loinc'] == loinc]\n",
    "\n",
    "            # Handling if interpretation not suitable for the LOINC code\n",
    "            if interpretation not in loinc_hpo['interpretation'].unique() :\n",
    "                print('Interpretation is invalid, please check if you have used correct interpretation.')\n",
    "                interpretation_sugg = df[df['loinc']==loinc]['interpretation'].drop_duplicates()\n",
    "                print('Available interpretation for code', loinc, ' : ', (' or ').join(interpretation_sugg.values) , '\\n')\n",
    "                return []\n",
    "            \n",
    "            loinc_hpo = loinc_hpo[loinc_hpo['interpretation'] == interpretation]['hpoTermId'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', loinc_hpo, '\\n')\n",
    "            return loinc_hpo\n",
    "        else:\n",
    "            print('LOINC data is missing either code / interpretation.')\n",
    "            print('Example : LOINC:721-1|H for Qn lab examination OR LOINC:721-1|NEG for Nominal / Ordinal Lab Examination', '\\n')\n",
    "            return []\n",
    "        \n",
    "    # SNOMED-CT case\n",
    "    elif 'SNOMEDCT:' in clinical_data:\n",
    "        if clinical_data not in df['SNOMED_CT_ID'].unique() :\n",
    "            print('This SNOMED-CT code is not a clinical finding mapped with HPO, please check the SNOMED to OMIM for diagnosis mapping.')\n",
    "            snomed_sugg = df[df['SNOMED_CT_ID'].str.contains(clinical_data.strip('SNOMEDCT:'))]['SNOMED_CT_ID'].drop_duplicates()\n",
    "            print('Sugggestion : It is possible that you mean any of this code:', (', ').join(snomed_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            snomed_hpo = df[df['SNOMED_CT_ID'] == clinical_data]['HPO_ID'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(snomed_hpo), ' HPO code : ', (', ').join(snomed_hpo), '\\n')\n",
    "            return snomed_hpo\n",
    "        \n",
    "    # Not recognized case\n",
    "    else:\n",
    "        print('The terminology is not recognized, please check if you have used correct terminology.')\n",
    "        print('Example : LOINC:2862-1|L for Qn lab examination OR LOINC:725-2|NEG for categoric lab examination of SNOMEDCT:48610005 for Clinical Finding', '\\n')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snomed_orpha_parser(clinical_data, df):\n",
    "    print('Trying to parse ORPHA from SNOMED-CT', clinical_data)\n",
    "    \n",
    "    if 'SNOMEDCT:' in clinical_data:\n",
    "        if clinical_data not in df['code'].unique() :\n",
    "            print('This SNOMED-CT code is not a clinical finding mapped with ORPHA, please check the SNOMED to ORPHA for diagnosis mapping.')\n",
    "            snomed_sugg = df[df['code'].str.contains(clinical_data.strip('SNOMEDCT:'))]['code'].drop_duplicates()\n",
    "            print('Sugggestion : It is possible that you mean any of this code:', (', ').join(snomed_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            snomed_orpha = df[df['code'] == clinical_data]['orphanet_map'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(snomed_orpha), ' ORPHA code : ', (', ').join(snomed_orpha), '\\n')\n",
    "            return snomed_orpha\n",
    "        \n",
    "    else :\n",
    "        print('The terminology is not recognized, please check if you have used correct terminology.')\n",
    "        print('Allowable format : SNOMEDCT disorder semantic only SNOMEDCT:1212005', '\\n')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMIM Parser used for diagnosis related terminology such as ICD-10, ORPHA, SNOMED-CT\n",
    "def omim_parser(clinical_data,df):\n",
    "    print('Trying to parse OMIM from terminology', clinical_data)\n",
    "\n",
    "    # ICD-10 case\n",
    "    if 'ICD-10:' in clinical_data:\n",
    "        if clinical_data not in df['ICD10'].unique() :\n",
    "            print('ICD-10 data is not found in the database, please check the exact ICD-10 code.')\n",
    "            icd_sugg = df[df['ICD10'].str.contains(clinical_data.strip('ICD-10:'))]['ICD10'].drop_duplicates()\n",
    "            print('Did you mean any of this code:', (', ').join(icd_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            icd_omim = df[df['ICD10'] == clinical_data]['OMIM'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(icd_omim), ' OMIM code : ', (', ').join(icd_omim), '\\n')\n",
    "            return icd_omim\n",
    "        \n",
    "    # ORPHA case\n",
    "    elif 'ORPHA:' in clinical_data:\n",
    "        if clinical_data not in df['ORPHA'].unique() :\n",
    "            print('ORPHA data is not found in the database, please check the exact ORPHA code.')\n",
    "            orpha_sugg = df[df['ORPHA'].str.contains(clinical_data.strip('ORPHA:'))]['ORPHA'].drop_duplicates()\n",
    "            print('Did you mean any of this code:', (', ').join(orpha_sugg.values) , '?\\n')\n",
    "            return []\n",
    "        else : \n",
    "            orpha_hpo = df[df['ORPHA'] == clinical_data]['OMIM'].to_list()\n",
    "            print('Parsing of', clinical_data, 'successful with result of :', len(orpha_hpo), ' OMIM code : ', (', ').join(orpha_hpo), '\\n')\n",
    "            return orpha_hpo\n",
    "    \n",
    "    else:\n",
    "        print('The terminology is not recognized, please check the input format.')\n",
    "        print('Allowable format is : ICD-10:xxxx OR ORPHA:xxxxx for clinical disorder', '\\n')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to parse HPO from terminology LOINC:2862-1|L\n",
      "Parsing of LOINC:2862-1|L successful with result of : ['HP:0003073'] \n",
      "\n",
      "Trying to parse HPO from terminology SNOMEDCT:249627005\n",
      "Parsing of SNOMEDCT:249627005 successful with result of : 1  HPO code :  HP:0002249 \n",
      "\n",
      "Result of : 2 HPO code(s) from loinc_hpo_example and snomed_hpo_example\n",
      "\n",
      "Trying to parse OMIM from terminology ICD-10:E75.2\n",
      "Parsing of ICD-10:E75.2 successful with result of : 46  OMIM code :  OMIM:228000, OMIM:603896, OMIM:203450, OMIM:616140, OMIM:613926, OMIM:613925, OMIM:604004, OMIM:608804, OMIM:612233, OMIM:260600, OMIM:300523, OMIM:312080, OMIM:611721, OMIM:615281, OMIM:272200, OMIM:221790, OMIM:607616, OMIM:245200, OMIM:611722, OMIM:613724, OMIM:231005, OMIM:607694, OMIM:257200, OMIM:615889, OMIM:617762, OMIM:271900, OMIM:250100, OMIM:231000, OMIM:213900, OMIM:257220, OMIM:607625, OMIM:608013, OMIM:617899, OMIM:612438, OMIM:221820, OMIM:169500, OMIM:249900, OMIM:156310, OMIM:610539, OMIM:230900, OMIM:612951, OMIM:609136, OMIM:230800, OMIM:615651, OMIM:617560, OMIM:301500 \n",
      "\n",
      "Trying to parse OMIM from terminology ORPHA:848\n",
      "Parsing of ORPHA:848 successful with result of : 2  OMIM code :  OMIM:613985, OMIM:603902 \n",
      "\n",
      "Trying to parse ORPHA from SNOMED-CT SNOMEDCT:11179002\n",
      "Parsing of SNOMEDCT:11179002 successful with result of : 1  ORPHA code :  ORPHA:367 \n",
      "\n",
      "Trying to parse OMIM from terminology ORPHA:367\n",
      "Parsing of ORPHA:367 successful with result of : 2  OMIM code :  OMIM:263570, OMIM:232500 \n",
      "\n",
      "Result of : 4 OMIM code(s) from Diagnosis Code\n",
      "Result of : 4 unique OMIM code(s) from Diagnosis Code\n"
     ]
    }
   ],
   "source": [
    "# Example of hpo_parser for Clinical Finding (LOINC & SNOMED)\n",
    "hpo_result = []\n",
    "loinc_hpo_example = hpo_parser('LOINC:2862-1|L', loinc2hpo_df)\n",
    "snomed_hpo_example = hpo_parser('SNOMEDCT:249627005', snomed2hpo_df)\n",
    "\n",
    "# Initiate List or Append\n",
    "hpo_result.extend(loinc_hpo_example)\n",
    "hpo_result.extend(snomed_hpo_example)\n",
    "\n",
    "print(\"Result of :\", len(hpo_result), \"HPO code(s) from loinc_hpo_example and snomed_hpo_example\\n\")\n",
    "\n",
    "# Example of OMIM Parser for Diagnosis\n",
    "omim_hpo_result = []\n",
    "icd_omim_example = omim_parser('ICD-10:E75.2', icd10omim_df)\n",
    "orpha_omim_example = omim_parser('ORPHA:848', orpha2omim_df)\n",
    "snomed_orpha_example = snomed_orpha_parser('SNOMEDCT:11179002', snomed2orpha_df)\n",
    "\n",
    "snomed_omim_example = []\n",
    "for i in range(len(snomed_orpha_example)) :\n",
    "    snomed_omim_example = snomed_omim_example + omim_parser(snomed_orpha_example[i], orpha2omim_df)\n",
    "\n",
    "# Extend the result, but exclude the ICD OMIM since the code itself is unspecific and give too many unspecific result\n",
    "# omim_hpo_result.extend(icd_omim_example)    \n",
    "omim_hpo_result.extend(orpha_omim_example)\n",
    "omim_hpo_result.extend(snomed_omim_example)\n",
    "\n",
    "print(\"Result of :\", len(omim_hpo_result), \"OMIM code(s) from Diagnosis Code\")\n",
    "print(\"Result of :\", len(set(omim_hpo_result)), \"unique OMIM code(s) from Diagnosis Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omim_hpo_intersecter(omim_list, df, hpo_specification=[], diagnosis_phen_sim_threshold=0.8):\n",
    "    ## Explanation : \n",
    "    \n",
    "    # 1. hpo_specification is further curation to select filter out relevant OMIM diagnosis\n",
    "    # Suppose in hpo_specification there are HP:0001268 - Mental Retardation\n",
    "    # This will furtherly curate the related OMIM diagnosis that contain HP:0001268, and expand all the related HPO possible\n",
    "\n",
    "    # 2. diagnosis_phen_sim_threshold is a threshold to determine the similarity between the diagnosis\n",
    "    # Suppose you have 10 OMIM diagnosis code, and the threshold is 0.9, then the HPO code returned would be the one that occur at least 9 times\n",
    "    # If the threshold is 0.5, then the HPO code returned would be the one that occur at least 5 times\n",
    "    \n",
    "    # Number the OMIM code that will be check as phenotype relationship \n",
    "    disease_threshold = diagnosis_phen_sim_threshold * len(omim_list)\n",
    "    \n",
    "    # Check to filter the diagnosis that have the full specification of HPO inside the list\n",
    "    if len(hpo_specification) > 0:\n",
    "        hpo_specification = set(hpo_specification)\n",
    "        df = df[df['hpo_id'].isin(hpo_specification)].groupby('disease_id')\n",
    "    \n",
    "    # Result out the data that at least occur more than threshold\n",
    "    if len(omim_list) > 0:\n",
    "        omim_list = set(omim_list)\n",
    "        omim_hpo = df[df['disease_id'].isin(omim_list)]\n",
    "        disease_id = omim_hpo['disease_id'].to_list()\n",
    "        omim_list = omim_hpo['hpo_id'].to_list()\n",
    "        return omim_list, disease_id\n",
    "    \n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'isin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-221-63c63228648c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0momim_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisease_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0momim_hpo_intersecter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momim_hpo_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0momim2hpo_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhpo_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-220-21c3b4eaa8c5>\u001b[0m in \u001b[0;36momim_hpo_intersecter\u001b[1;34m(omim_list, df, hpo_specification, diagnosis_phen_sim_threshold)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momim_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0momim_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momim_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0momim_hpo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'disease_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momim_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mdisease_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0momim_hpo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'disease_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0momim_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0momim_hpo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hpo_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ivan-RTX2080\\.conda\\envs\\datascience\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m    753\u001b[0m             \u001b[1;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'isin'"
     ]
    }
   ],
   "source": [
    "omim_list, disease_id = omim_hpo_intersecter(omim_hpo_result, omim2hpo_df, hpo_result, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'OMIM:312080', 'OMIM:607694', 'OMIM:608013', 'OMIM:609136'}, 161)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_id, len(omim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If LOINC / SNOMED with only single result --> return back only the HPO, \n",
    "# But if diagnosis code with multiple result --> store it as temporary data and then find the similarity of phenotype first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
