{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: o365 2.0.16 has a non-standard dependency specifier tzlocal<3.*,>=1.5.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of o365 or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ivan-rtx2080\\.conda\\envs\\datascience\\lib\\site-packages (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: o365 2.0.16 has a non-standard dependency specifier tzlocal<3.*,>=1.5.0. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of o365 or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# SNOMED-CT International Version Used\n",
    "version = '20240301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SNOMED CT concept, description, and language refset file\n",
    "concept = pd.read_table('sct2_Concept_Snapshot_INT_{version}.txt'.format(version = version), sep='\\t')\n",
    "description = pd.read_table('sct2_Description_Snapshot-en_INT_{version}.txt'.format(version = version), sep='\\t')\n",
    "language_ref_set = pd.read_table(os.path.join('..', 'RefSet', 'Language' , 'der2_cRefset_LanguageSnapshot-en_INT_{version}.txt'.format(version = version)), sep='\\t')\n",
    "\n",
    "# Read the SNOMED CT >< Orphanet Map from Snapshot\\Refset\\Map\\der2_sRefset_OrphanetSimpleMapSnapshot_INT_20230731.txt - The latest version at March 2024 is 20230731 map\n",
    "orphanet_map = pd.read_table('der2_sRefset_OrphanetSimpleMapSnapshot_INT_20230731.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Concept, Description, and Language Refset file from SNOMED CT International RF2 Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept : ['id', 'effectiveTime', 'active', 'moduleId', 'definitionStatusId'] 511088 rows\n",
      "description : ['id', 'effectiveTime', 'active', 'moduleId', 'conceptId', 'languageCode', 'typeId', 'term', 'caseSignificanceId'] 1622713 rows\n",
      "language_ref_set : ['id', 'effectiveTime', 'active', 'moduleId', 'refsetId', 'referencedComponentId', 'acceptabilityId'] 3173754 rows\n",
      "\n",
      "\n",
      "Total concept :  511088  | Total active :  366651  | Delta :  144437\n",
      "Total description :  1622713  | Total active :  1328439  | Delta :  294274\n",
      "Active Concept :  366651\n",
      "\n",
      "\n",
      "Active Description :  969140\n",
      "FSN Description :  366632\n",
      "Synonym Description :  602508\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f1816cea5952>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_language_ref_set['preferability'] = active_language_ref_set['acceptabilityId'].apply(lambda x: 'Preferred' if x==900000000000548007 else 'Acceptable')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Language Refset from active concept & active description :  1139646\n",
      "Trimmed / drop duplicates :  609376\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f1816cea5952>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_description['type'] = active_description['typeId'].apply(lambda x: 'FSN' if x==900000000000003001 else 'Synonym')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Description from active concept :  969140\n",
      "Trimmed / drop duplicates :  969140\n"
     ]
    }
   ],
   "source": [
    "# Explore how many row in concept, description, and language refset file\n",
    "print('concept :', [x for x in concept.columns], len(concept), 'rows')\n",
    "print('description :', [x for x in description.columns], len(description), 'rows')\n",
    "print('language_ref_set :', [x for x in language_ref_set.columns], len(language_ref_set), 'rows')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print Statistic of the concept and description\n",
    "print(\"Total concept : \", len(concept), \" | Total active : \", len(concept[concept['active'] == 1]), \" | Delta : \", len(concept) - len(concept[concept['active'] == 1]))\n",
    "print(\"Total description : \", len(description), \" | Total active : \", len(description[description['active'] == 1]), \" | Delta : \", len(description) - len(description[description['active'] == 1]))\n",
    "\n",
    "## Subset and print active concept number\n",
    "active_concept = concept[concept['active'] == 1]\n",
    "concept_list = active_concept['id'].tolist()\n",
    "print(\"Active Concept : \", len(concept_list))\n",
    "print(\"\\n\")\n",
    "\n",
    "## Active description contained in Active concept\n",
    "filtered_description = description[description['conceptId'].isin(concept_list)]\n",
    "active_description = filtered_description[filtered_description['active'] == 1]\n",
    "fsn_description = active_description[active_description['typeId'] == 900000000000003001]\n",
    "synonym_description = active_description[active_description['typeId'] == 900000000000013009]\n",
    "\n",
    "print('Active Description : ', len(active_description))\n",
    "print('FSN Description : ', len(fsn_description))\n",
    "print('Synonym Description : ', len(synonym_description))\n",
    "print(\"\\n\")\n",
    "\n",
    "## active language refset\n",
    "filtered_language_ref_set = language_ref_set[language_ref_set['referencedComponentId'].isin(synonym_description['id'].tolist())]\n",
    "active_language_ref_set = filtered_language_ref_set[filtered_language_ref_set['active'] == 1]\n",
    "\n",
    "## Value Counts\n",
    "## 900000000000548007 = Preferred, 900000000000549004 = Acceptable\n",
    "# active_language_ref_set['acceptabilityId'].value_counts()\n",
    "\n",
    "active_language_ref_set['preferability'] = active_language_ref_set['acceptabilityId'].apply(lambda x: 'Preferred' if x==900000000000548007 else 'Acceptable')\n",
    "\n",
    "trimmed_language_ref_set = active_language_ref_set[['referencedComponentId', 'preferability']].drop_duplicates()\n",
    "print('Active Language Refset from active concept & active description : ', len(active_language_ref_set))\n",
    "print('Trimmed / drop duplicates : ', trimmed_language_ref_set['preferability'].count())\n",
    "print(\"\\n\")\n",
    "\n",
    "## active description\n",
    "## 900000000000003001 = FSN\n",
    "active_description['type'] = active_description['typeId'].apply(lambda x: 'FSN' if x==900000000000003001 else 'Synonym')\n",
    "\n",
    "trimmed_active_description = active_description[['id', 'conceptId', 'term', 'type']].drop_duplicates()\n",
    "print('Active Description from active concept : ', len(active_description))\n",
    "print('Trimmed / drop duplicates : ', len(trimmed_active_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-959290f13778>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fsn_description['parent'] = fsn_description['term'].apply(lambda x: x.split('(')[1].replace(')', ''))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hierarchy</th>\n",
       "      <th>system</th>\n",
       "      <th>code</th>\n",
       "      <th>display</th>\n",
       "      <th>type</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>organism</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>101009</td>\n",
       "      <td>Quilonia ethiopica (organism)</td>\n",
       "      <td>FSN</td>\n",
       "      <td>20240301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>organism</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>101009</td>\n",
       "      <td>Quilonia ethiopica</td>\n",
       "      <td>Synonym - Preferred</td>\n",
       "      <td>20240301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>substance</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>102002</td>\n",
       "      <td>Hemoglobin Okaloosa</td>\n",
       "      <td>Synonym - Preferred</td>\n",
       "      <td>20240301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>substance</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>102002</td>\n",
       "      <td>Hb 48(CD7), Leu-arg</td>\n",
       "      <td>Synonym - Acceptable</td>\n",
       "      <td>20240301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>substance</td>\n",
       "      <td>http://snomed.info/sct</td>\n",
       "      <td>102002</td>\n",
       "      <td>Haemoglobin Okaloosa</td>\n",
       "      <td>Synonym - Preferred</td>\n",
       "      <td>20240301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hierarchy                  system    code                        display  \\\n",
       "0   organism  http://snomed.info/sct  101009  Quilonia ethiopica (organism)   \n",
       "1   organism  http://snomed.info/sct  101009             Quilonia ethiopica   \n",
       "2  substance  http://snomed.info/sct  102002            Hemoglobin Okaloosa   \n",
       "3  substance  http://snomed.info/sct  102002            Hb 48(CD7), Leu-arg   \n",
       "4  substance  http://snomed.info/sct  102002           Haemoglobin Okaloosa   \n",
       "\n",
       "                   type   version  \n",
       "0                   FSN  20240301  \n",
       "1   Synonym - Preferred  20240301  \n",
       "2   Synonym - Preferred  20240301  \n",
       "3  Synonym - Acceptable  20240301  \n",
       "4   Synonym - Preferred  20240301  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create combined DataFrame\n",
    "combined = pd.merge(trimmed_active_description, trimmed_language_ref_set, left_on='id', right_on='referencedComponentId', how='left')\n",
    "combined = combined.drop(['referencedComponentId', 'id'], axis=1).sort_values('conceptId').drop_duplicates()\n",
    "\n",
    "## Combine type and preferability\n",
    "combined['type_preferability'] = combined['type'] + ' - ' + combined['preferability']\n",
    "combined.loc[combined['type_preferability'].isnull(), 'type_preferability'] = combined['type']\n",
    "\n",
    "## Get Semantic Tag from FSN and save it in 'parent' column from FSN\n",
    "fsn_description['parent'] = fsn_description['term'].apply(lambda x: x.split('(')[1].replace(')', ''))\n",
    "raw_table_parent = fsn_description[['conceptId', 'parent']].drop_duplicates()\n",
    "\n",
    "## Left join to get full table\n",
    "combined = pd.merge(combined, raw_table_parent, left_on='conceptId', right_on='conceptId', how='left')\n",
    "# combined.head()\n",
    "\n",
    "## Finishing touch\n",
    "final_df = pd.DataFrame(columns = ['hierarchy', 'system', 'code', 'display', 'type', 'version'] )\n",
    "final_df[['hierarchy', 'code', 'display', 'type']] = combined[['parent', 'conceptId', 'term', 'type_preferability']]\n",
    "final_df['system'] = 'http://snomed.info/sct'\n",
    "final_df['version'] = version\n",
    "final_df.head()\n",
    "\n",
    "### Convert to final_df to csv (Full SNOMED CT List)\n",
    "# final_df.to_csv('Full Table Ready SNOMED-CT.csv', index=False, sep=';')\n",
    "\n",
    "### Apply filter for FSN and Synonym - Preferred Description\n",
    "# filter = ['FSN', 'Synonym - Preferred']\n",
    "# final_df = final_df[final_df['type'].isin(filter)]\n",
    "# final_df.to_csv('Filtered Table Ready SNOMED-CT.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSN number : 366632\n",
      "Preferred Syn number :  366621\n",
      "Acceptable Syn number :  138687\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Reduce repetition of similar row - Tile FSN and Synonym horizontally\n",
    "fsn = final_df[final_df['type'] == 'FSN']\n",
    "preferred = final_df[final_df['type'] == 'Synonym - Preferred'].drop_duplicates(subset=['code'])\n",
    "acceptable = final_df[final_df['type'] == 'Synonym - Acceptable'].drop_duplicates(subset=['code'])\n",
    "\n",
    "## Create FSN Column Subset\n",
    "cut_fsn = pd.DataFrame()\n",
    "cut_fsn[['hierarchy', 'system', 'code', 'fsn', 'version']] = fsn[['hierarchy', 'system', 'code', 'display', 'version']]\n",
    "\n",
    "## Create Preferred Synonym Column Subset\n",
    "cut_preferred = pd.DataFrame()\n",
    "cut_preferred[['code', 'preferred']] = preferred[['code', 'display']]\n",
    "\n",
    "## Create Acceptable Synonym Column Subset\n",
    "cut_acceptable = pd.DataFrame()\n",
    "cut_acceptable[['code', 'acceptable']] = acceptable[['code', 'display']]\n",
    "\n",
    "## Statistic \n",
    "print('FSN number :', len(cut_fsn))\n",
    "print('Preferred Syn number : ', len(cut_preferred))\n",
    "print('Acceptable Syn number : ', len(cut_acceptable))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge column subset\n",
    "trimmed_row = pd.merge(cut_fsn, cut_preferred, left_on='code', right_on='code', how='left')\n",
    "trimmed_row = pd.merge(trimmed_row, cut_acceptable, left_on='code', right_on='code', how='left')\n",
    "# trimmed_row.to_csv('Concise SNOMED Table.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with Orphanet Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join from referencedComponentId\n",
    "combined_orphanet = pd.merge(trimmed_row, orphanet_map, left_on='code', right_on='referencedComponentId', how='left')\n",
    "\n",
    "# combined_orphanet with non null mapTarget\n",
    "combined_orphanet = combined_orphanet[combined_orphanet['mapTarget'].notnull()]\n",
    "combined_orphanet['orphanet_map'] = combined_orphanet['mapTarget'].apply(lambda x: str(x).replace('.0', ''))\n",
    "\n",
    "# Drop all column from the der2_sRefset_OrphanetSimpleMapSnapshot_INT_20230731.txt except mapTarget\n",
    "combined_orphanet = combined_orphanet.drop(['id', 'effectiveTime', 'active', 'moduleId', 'refsetId', 'referencedComponentId', 'mapTarget'], axis=1)\n",
    "# combined_orphanet.head()\n",
    "\n",
    "# Add prefix ORPHA and SNOMED to code and orphanet_map\n",
    "combined_orphanet['code'] = 'SNOMEDCT:' + combined_orphanet['code'].astype(str)\n",
    "combined_orphanet['orphanet_map'] = 'ORPHA:' + combined_orphanet['orphanet_map'].astype(str)\n",
    "\n",
    "# Save to TSV\n",
    "combined_orphanet.to_csv(os.path.join('subset', 'snomed2orpha_subset.tsv'), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f355011d391234d33b3c3c4e46934f76cebb4e69043aedc0cff87869ebfc4d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
